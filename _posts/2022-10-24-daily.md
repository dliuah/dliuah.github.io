---
title: "daily"
date: 2022-10-24
---

Andrew Ng suggested gradient descent for linear regression when the size is not smaller than 10^6. However, it turned out batch **gradient descent** is very slow. Stochasitc GD can be helpful, but the 
established library doesn't provide the intermediate results and makes me less confident in the result. It turns out SVD is the best solution.
Fast and also stable. GD can be useful in neural network.

The stock market is crashing today. Things may be tighter.

The push up really works. I have been doing it almost everyday for the past 2 weeks. And my backache also becomes less severe. It's amazing that this simple exercise can have such impact on my body. Let's see when I can do 50 each day. Now is 30.
